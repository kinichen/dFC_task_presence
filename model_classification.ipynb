{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from contrastive import CPCA\t# $ pip3 install contrastive\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# set for your own directory\n",
    "my_filepath = \"/Users/kinichen/Summer_dFC/Datasets/ds003465_task-Axcpt_Time-Freq.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset for 1 task paradigm assessed by 1 method for all subjects (1 run)\n",
    "dFC = np.load(my_filepath, allow_pickle=True)\n",
    "dFC_dict = dFC.item() # extract the dictionary from np array\n",
    "\n",
    "X = dFC_dict[\"X\"]\n",
    "y = dFC_dict[\"y\"]\n",
    "subj_label = dFC_dict[\"subj_label\"]\n",
    "method = dFC_dict[\"measure_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_reduction_train(X, model_class, n_components, Y=None, alpha=1):\n",
    "\t\"\"\"\n",
    "\tFit dimension reduction pipeline on train data, and return both transformed X and the reusable pipeline.\n",
    "\t\n",
    "\tParameters:\n",
    "\t\tX: array-like, shape (n_samples_train, n_features)\n",
    "\t\tmodel_class: class (PCA, CCA, CPCA, or UMAP)\n",
    "\t\tn_components: number of components to keep on outermost layer (not PCA if\n",
    "\t\t\tit is used as a preprocessing step)\n",
    "\t\tY: for supervised CCA or CPCA background\n",
    "\t\talpha: CPCA contrastive parameter\n",
    "\t\t\n",
    "\tReturns:\n",
    "\t\tX_reduced: transformed training data\n",
    "\t\tpipeline: object to reuse to transform test data\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tscaler_X = StandardScaler()\n",
    "\tX_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "\tif model_class.__name__ == 'PCA':\n",
    "\t\tmodel = model_class(n_components=n_components)\n",
    "\t\tpipeline = Pipeline([\n",
    "\t\t\t('scaler', scaler_X),\n",
    "\t\t\t('pca', model)\n",
    "\t\t])\n",
    "\t\tX_reduced = pipeline.fit_transform(X)\n",
    "\n",
    "\telif model_class.__name__ == 'CCA':\n",
    "\t\t# Note: it only makes sense to use supervised CCA with labels Y=y. If\n",
    "\t\t# using Y=X_rest, the reduced subspace does not enhance task-specific\n",
    "\t\t# features, but instead returns the shared subspace between task and rest.\n",
    "\t\tif Y is None:\n",
    "\t\t\traise ValueError(\"CCA requires supervised labels Y.\")\n",
    "\n",
    "\t\t# Preprocess labels into \"2D\" array with shape (n_samples, 1), then OneHotEncoder\n",
    "\t\ty = OneHotEncoder(sparse_output=False).fit_transform(Y.reshape(-1, 1))\n",
    "\n",
    "\t\t# PCA before CCA\n",
    "\t\tpca = PCA(n_components=1000)\n",
    "\t\tX_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "\t\tcca = model_class(n_components=n_components)\n",
    "\t\tX_cca, _ = cca.fit_transform(X_pca, y)\n",
    "\n",
    "\t\t# Store fitted pipeline parts manually into a dictionary\n",
    "\t\tpipeline = {\n",
    "\t\t\t'scaler': scaler_X,\n",
    "\t\t\t'pca': pca,\n",
    "\t\t\t'cca': cca,\n",
    "\t\t\t'label_encoder': y  # just for reference if needed\n",
    "\t\t}\n",
    "\t\tX_reduced = X_cca\n",
    "\n",
    "\telif model_class.__name__ == 'CPCA':\n",
    "\t\tif Y is None:\n",
    "\t\t\traise ValueError(\"CPCA requires background dataset Y.\")\n",
    "\t\t\n",
    "\t\tscaler_Y = StandardScaler()\n",
    "\t\tY_scaled = scaler_Y.fit_transform(Y)\n",
    "\n",
    "\t\t# Note: the CPCA class intrinsically applies PCA to reduce to 1000 \n",
    "  \t\t# components first, so for consistency on test data, do this explicitly\n",
    "\t\tpca = PCA(n_components=1000)\n",
    "\t\tX_pca = pca.fit_transform(X_scaled)\n",
    "\t\tY_pca = pca.transform(Y_scaled)\t# transform Y into the same PCA feature space\n",
    "\n",
    "\t\tcpca = model_class(n_components=n_components)\n",
    "\t\tX_cpca = cpca.fit_transform(X_pca, Y_pca, \n",
    "\t\t\t\t\t\t\talpha_selection='manual', alpha_value=alpha)\n",
    "\t\t\n",
    "\t\tpipeline = {\n",
    "\t\t\t'scaler_X': scaler_X,\t# Don't store scaler_Y, as it is not needed for test data\n",
    "\t\t\t'pca': pca,\n",
    "   \t\t\t'cpca': cpca,\n",
    "\t\t\t'alpha': alpha \n",
    "\t\t}\n",
    "\t\tX_reduced = X_cpca\n",
    "\n",
    "\telif model_class.__name__ == 'UMAP':\n",
    "\t\tpca = PCA(n_components=1000)\n",
    "\t\tX_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "\t\tumap_model = umap.UMAP(n_neighbors=50, min_dist=0.1, \n",
    "\t\t\t\t\t\t\t   n_components=n_components, random_state=25)\n",
    "\t\tX_umap = umap_model.fit_transform(X_pca)\n",
    "\n",
    "\t\tpipeline = {\n",
    "\t\t\t'scaler': scaler_X,\n",
    "\t\t\t'pca': pca,\n",
    "\t\t\t'umap': umap_model\n",
    "\t\t}\n",
    "\t\tX_reduced = X_umap\n",
    "\n",
    "\telse:\n",
    "\t\traise ValueError(\"Only PCA, CCA, CPCA, UMAP are supported right now.\")\n",
    "\n",
    "\treturn X_reduced, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_reduction_test(X, pipeline):\n",
    "\t\"\"\"\n",
    "\tReturn the transformed test data using the fitted model pipeline.\n",
    "\t\n",
    "\tParameters:\n",
    "\t\tX: array-like test data, shape (n_samples_test, n_features)\n",
    "\t\tpipeline: fitted model pipeline (PCA, CCA, CPCA, or UMAP)\n",
    "\t\tY: optional labels (needed for supervised CCA or CPCA background)\n",
    "\t\t\n",
    "\tReturns:\n",
    "\t\tX_reduced: transformed test data\n",
    "\t\"\"\"\n",
    "\tif isinstance(pipeline, Pipeline):  # only pure PCA used a Pipeline object\n",
    "\t\tX_reduced = pipeline.transform(X)\n",
    "\t\t\n",
    "\telif 'cca' in pipeline:\n",
    "\t\tX_scaled = pipeline['scaler'].transform(X)\n",
    "\t\tX_pca = pipeline['pca'].transform(X_scaled)\n",
    "\t\tX_reduced = pipeline['cca'].transform(X_pca)\n",
    "\n",
    "\telif 'cpca' in pipeline:\n",
    "\t\tX_scaled = pipeline['scaler_X'].transform(X)\n",
    "\t\tX_pca = pipeline['pca'].transform(X_scaled)\n",
    "\t\tX_reduced = pipeline['cpca'].transform(X_pca,\n",
    "\t\t\t\t\t\talpha_selection='manual', alpha_value=pipeline['alpha'])\n",
    "\n",
    "\telif 'umap' in pipeline:\n",
    "\t\tX_scaled = pipeline['scaler'].transform(X)\n",
    "\t\tX_pca = pipeline['pca'].transform(X_scaled)\n",
    "\t\tX_reduced = pipeline['umap'].transform(X_pca)\n",
    "\n",
    "\telse:\n",
    "\t\traise ValueError(\"Only PCA, CCA, CPCA and UMAP are supported right now.\")\n",
    "\t\n",
    "\treturn X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(classifier, X_train, y_train, X_test, y_test):\n",
    "\t\"\"\"\n",
    "\tEvaluate the performance of a fitted classifier on train and test data.\n",
    "\t\"\"\"\n",
    "\ty_train_pred = classifier.predict(X_train)\t# binary\n",
    "\ty_train_prob = classifier.predict_proba(X_train)[:, 1]\t# probabilities of task\n",
    "\ty_test_pred = classifier.predict(X_test)\n",
    "\ty_test_prob = classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\ttrain_accuracy = round(balanced_accuracy_score(y_train, y_train_pred), 3)\n",
    "\ttrain_auc = round(roc_auc_score(y_train, y_train_prob), 3)\n",
    "\ttest_accuracy = round(balanced_accuracy_score(y_test, y_test_pred), 3)\n",
    "\ttest_auc = round(roc_auc_score(y_test, y_test_prob), 3)\t# evaluates how well the\n",
    "\t# model predicts the probability of the positive class (1 = task). \n",
    " \t# for this AUC, 0.5 = random guess\n",
    "\treturn train_accuracy, train_auc, test_accuracy, test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_pipeline(\n",
    "\tX, y,\n",
    "\tmodel_class, n_components,\n",
    "\tclassifier_type='logistic',\n",
    "\tclassifier_kwargs=None,\n",
    "\tn_splits=5,\n",
    "\talpha_list=None,\n",
    "\trandom_state=42,\n",
    "\tverbose=True\n",
    "\t):\n",
    "\t\"\"\"\n",
    "\tCross-validate a dimensionality reduction + classifier pipeline.\n",
    "\n",
    "\tSupports PCA, CCA, CPCA, and UMAP with Logistic Regression or SVM.\n",
    "\tFor CPCA, the function searches over multiple alpha values and selects the best one\n",
    "\tper fold based on test accuracy.\n",
    "\n",
    "\tParameters:\n",
    "\t\tX, y: input data and binary labels\n",
    "\t\tmodel_class: PCA, CCA, CPCA, or UMAP\n",
    "\t\tn_components: number of components to reduce to\n",
    "\t\tclassifier_type: 'logistic' or 'svm'\n",
    "\t\tclassifier_kwargs: optional keyword arguments (in a dictionary) for classifier\n",
    "\t\tn_splits: number of CV folds\n",
    "\t\talpha_list: list of alpha values if using CPCA\n",
    "\t\trandom_state: for reproducibility\n",
    "\t\tverbose: if True, prints progress\n",
    "\n",
    "\tPrints:\n",
    "\t\tA dictionary storing average train and test accuracy and AUC across folds.\n",
    "\t\"\"\"\n",
    "\tskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\ttrain_accs, train_aucs, test_accs, test_aucs = [], [], [], []\t\n",
    " \t# stores accuracy and AUC scores for each fold\n",
    "\n",
    "\tif classifier_kwargs is None:\t# default empty dictionary for classifier parameters\n",
    "\t\tclassifier_kwargs = {}\n",
    "\n",
    "\tfor fold_idx, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "\t\tX_train, X_test = X[train_idx], X[test_idx]\n",
    "\t\ty_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "\t\tif model_class.__name__ == 'CPCA':\n",
    "\t\t\tbest_acc = 0\n",
    "\t\t\tbest_X_train_reduced = None\n",
    "\t\t\tbest_X_test_reduced = None\n",
    "\t\t\tbest_alpha = None\n",
    "   \n",
    "\t\t\tif alpha_list is None:\n",
    "\t\t\t\talpha_list = [0.1, 1, 10]\n",
    "\t\n",
    "\t\t\tfor alpha in alpha_list:\n",
    "\t\t\t\tX_train_rest = X_train[y_train == 0]\n",
    "\t\t\t\tX_train_reduced, pipeline = dim_reduction_train(\n",
    "\t\t\t\t\tX_train, model_class, n_components=n_components,\n",
    "\t\t\t\t\tY=X_train_rest, alpha=alpha\n",
    "\t\t\t\t)\n",
    "\t\t\t\tX_test_reduced = dim_reduction_test(X_test, pipeline)\n",
    "\n",
    "\t\t\t\tif classifier_type == 'logistic':\n",
    "\t\t\t\t\tclf = LogisticRegression(random_state=random_state, \n",
    "\t\t\t\t\t\t\t**classifier_kwargs)\n",
    "\t\t\t\telif classifier_type == 'svm':\n",
    "\t\t\t\t\tclf = SVC(probability=True, random_state=random_state, \n",
    "\t\t\t   \t\t\t\t**classifier_kwargs)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\traise ValueError(\"Unsupported classifier type. Only 'logistic' and 'svm'.\")\n",
    "\n",
    "\t\t\t\tclf.fit(X_train_reduced, y_train)\n",
    "\t\t\t\ty_pred = clf.predict(X_test_reduced)\n",
    "\t\t\t\tacc = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "\t\t\t\tif acc > best_acc:\n",
    "\t\t\t\t\tbest_acc = acc\n",
    "\t\t\t\t\tbest_X_train_reduced = X_train_reduced\n",
    "\t\t\t\t\tbest_X_test_reduced = X_test_reduced\n",
    "\t\t\t\t\tbest_alpha = alpha\n",
    "\n",
    "\t\t\tX_train_reduced = best_X_train_reduced\n",
    "\t\t\tX_test_reduced = best_X_test_reduced\n",
    "   \n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(f\"Fold {fold_idx+1}: Best alpha = {best_alpha}\")\n",
    "\n",
    "\t\telse:\n",
    "\t\t\t# PCA, CCA, or UMAP\n",
    "\t\t\tif model_class.__name__ == 'CCA':\n",
    "\t\t\t\t# will do one-hot encoding to 2 features\n",
    "\t\t\t\tif n_components > len(np.unique(y_train)):\n",
    "\t\t\t\t\traise ValueError(\"Number of components for CCA cannot\",\n",
    "\t\t\t\t\t  \"exceed minimum number of features between X and Y.\")\n",
    "\t\t\t\tY_train = y_train\n",
    "\t\t\telse:\n",
    "\t\t\t\tY_train = None\n",
    "\n",
    "\t\t\tX_train_reduced, pipeline = dim_reduction_train(\n",
    "\t\t\t\tX_train, model_class, n_components=n_components, Y=Y_train)\n",
    "\t\t\tX_test_reduced = dim_reduction_test(X_test, pipeline)\n",
    "\n",
    "\t\tif classifier_type == 'logistic':\n",
    "\t\t\tclf = LogisticRegression(random_state=random_state, **classifier_kwargs)\n",
    "\t\telif classifier_type == 'svm':\n",
    "\t\t\tclf = SVC(probability=True, random_state=random_state, **classifier_kwargs)\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"Unsupported classifier type\")\n",
    "\n",
    "\t\tclf.fit(X_train_reduced, y_train)\n",
    "\n",
    "\t\ttrain_accuracy, train_auc, test_accuracy, test_auc = evaluate_performance(\n",
    "\t\t\tclf, X_train_reduced, y_train, X_test_reduced, y_test\n",
    "\t\t)\n",
    "  \n",
    "\t\ttrain_accs.append(train_accuracy)\n",
    "\t\ttrain_aucs.append(train_auc)\n",
    "\t\ttest_accs.append(test_accuracy)\n",
    "\t\ttest_aucs.append(test_auc)\n",
    "\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(f\"Fold {fold_idx+1}: Train Accuracy={train_accs[-1]}, Train\",\n",
    "\t\t \t\t\tf\"AUC={train_aucs[-1]}, Test Accuracy={test_accs[-1]},\",\n",
    "\t\t\t\t\tf\"Test AUC={test_aucs[-1]}\")\n",
    "\n",
    "\tscores = {\t# balanced accuracies across task vs rest classes\n",
    "\t\t'train_accuracy': round(np.mean(train_accs), 3),\n",
    "\t\t'train_auc': round(np.mean(train_aucs), 3),\n",
    "\t\t'test_accuracy': round(np.mean(test_accs), 3),\n",
    "\t\t'test_auc': round(np.mean(test_aucs), 3)\n",
    "\t}\n",
    "\tprint(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the classifiers (modify as needed)\n",
    "\n",
    "svm_params = {\n",
    "\t'kernel': 'rbf',\n",
    "\t'C': 1.0,\n",
    "\t'gamma': 'scale'\n",
    "}\n",
    "\n",
    "logistic_params = {\n",
    "\t'penalty': 'l1', \n",
    "\t'solver': 'saga', \n",
    "\t'max_iter': 5000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train Accuracy=0.675, Train AUC=0.728, Test Accuracy=0.651, Test AUC=0.69\n",
      "Fold 2: Train Accuracy=0.675, Train AUC=0.728, Test Accuracy=0.647, Test AUC=0.681\n",
      "Fold 3: Train Accuracy=0.675, Train AUC=0.727, Test Accuracy=0.664, Test AUC=0.69\n",
      "Fold 4: Train Accuracy=0.677, Train AUC=0.73, Test Accuracy=0.639, Test AUC=0.681\n",
      "Fold 5: Train Accuracy=0.679, Train AUC=0.732, Test Accuracy=0.65, Test AUC=0.684\n",
      "{'train_accuracy': 0.676, 'train_auc': 0.729, 'test_accuracy': 0.65, 'test_auc': 0.685}\n"
     ]
    }
   ],
   "source": [
    "# PCA + Logistic Regression with penalty\n",
    "# 328 components explains 90% variance in the dataset\n",
    "classification_pipeline(\n",
    "\tX, y, model_class=PCA, n_components=328,\n",
    "\tclassifier_type='logistic', classifier_kwargs=logistic_params,\n",
    "\tn_splits=5, random_state=42, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train Accuracy=0.733, Train AUC=0.89, Test Accuracy=0.712, Test AUC=0.778\n",
      "Fold 2: Train Accuracy=0.735, Train AUC=0.892, Test Accuracy=0.7, Test AUC=0.771\n",
      "Fold 3: Train Accuracy=0.73, Train AUC=0.892, Test Accuracy=0.707, Test AUC=0.796\n",
      "Fold 4: Train Accuracy=0.736, Train AUC=0.893, Test Accuracy=0.705, Test AUC=0.781\n",
      "Fold 5: Train Accuracy=0.735, Train AUC=0.891, Test Accuracy=0.717, Test AUC=0.773\n",
      "{'train_accuracy': 0.734, 'train_auc': 0.892, 'test_accuracy': 0.708, 'test_auc': 0.78}\n"
     ]
    }
   ],
   "source": [
    "# PCA + SVM\n",
    "classification_pipeline(\n",
    "\tX, y, model_class=PCA, n_components=328,\n",
    "\tclassifier_type='svm', classifier_kwargs=svm_params,\n",
    "\tn_splits=5, random_state=42, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train Accuracy=0.717, Train AUC=0.836, Test Accuracy=0.703, Test AUC=0.747\n",
      "Fold 2: Train Accuracy=0.72, Train AUC=0.84, Test Accuracy=0.686, Test AUC=0.735\n",
      "Fold 3: Train Accuracy=0.717, Train AUC=0.833, Test Accuracy=0.7, Test AUC=0.758\n",
      "Fold 4: Train Accuracy=0.717, Train AUC=0.836, Test Accuracy=0.698, Test AUC=0.749\n",
      "Fold 5: Train Accuracy=0.717, Train AUC=0.833, Test Accuracy=0.704, Test AUC=0.75\n",
      "{'train_accuracy': 0.718, 'train_auc': 0.836, 'test_accuracy': 0.698, 'test_auc': 0.748}\n"
     ]
    }
   ],
   "source": [
    "# PCA + SVM (ONLY 100 COMPONENTS)\n",
    "classification_pipeline(\n",
    "\tX, y, model_class=PCA, n_components=100,\n",
    "\tclassifier_type='svm', classifier_kwargs=svm_params,\n",
    "\tn_splits=5, random_state=42, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train Accuracy=0.597, Train AUC=0.61, Test Accuracy=0.593, Test AUC=0.592\n",
      "Fold 2: Train Accuracy=0.602, Train AUC=0.614, Test Accuracy=0.578, Test AUC=0.592\n",
      "Fold 3: Train Accuracy=0.595, Train AUC=0.608, Test Accuracy=0.599, Test AUC=0.626\n",
      "Fold 4: Train Accuracy=0.595, Train AUC=0.61, Test Accuracy=0.6, Test AUC=0.611\n",
      "Fold 5: Train Accuracy=0.593, Train AUC=0.61, Test Accuracy=0.61, Test AUC=0.622\n",
      "{'train_accuracy': 0.596, 'train_auc': 0.61, 'test_accuracy': 0.596, 'test_auc': 0.609}\n"
     ]
    }
   ],
   "source": [
    "# PCA + SVM (ONLY 2 COMPONENTS)\n",
    "classification_pipeline(\n",
    "\tX, y, model_class=PCA, n_components=2,\n",
    "\tclassifier_type='svm', classifier_kwargs=svm_params,\n",
    "\tn_splits=5, random_state=42, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train Accuracy=0.739, Train AUC=0.825, Test Accuracy=0.667, Test AUC=0.734\n",
      "Fold 2: Train Accuracy=0.736, Train AUC=0.826, Test Accuracy=0.674, Test AUC=0.737\n",
      "Fold 3: Train Accuracy=0.738, Train AUC=0.824, Test Accuracy=0.691, Test AUC=0.748\n",
      "Fold 4: Train Accuracy=0.742, Train AUC=0.826, Test Accuracy=0.664, Test AUC=0.727\n",
      "Fold 5: Train Accuracy=0.738, Train AUC=0.823, Test Accuracy=0.683, Test AUC=0.738\n",
      "{'train_accuracy': 0.739, 'train_auc': 0.825, 'test_accuracy': 0.676, 'test_auc': 0.737}\n"
     ]
    }
   ],
   "source": [
    "# Supervised CCA + Logistic Regression with penalty\n",
    "# Note: supervised CCA can only keep a maximum of 2 components.\n",
    "classification_pipeline(\n",
    "\tX, y, model_class=CCA, n_components=2,\n",
    "\tclassifier_type='logistic', classifier_kwargs=logistic_params,\n",
    "\tn_splits=5, random_state=42, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train Accuracy=0.733, Train AUC=0.801, Test Accuracy=0.683, Test AUC=0.719\n",
      "Fold 2: Train Accuracy=0.733, Train AUC=0.798, Test Accuracy=0.677, Test AUC=0.718\n",
      "Fold 3: Train Accuracy=0.735, Train AUC=0.796, Test Accuracy=0.698, Test AUC=0.739\n",
      "Fold 4: Train Accuracy=0.737, Train AUC=0.803, Test Accuracy=0.675, Test AUC=0.708\n",
      "Fold 5: Train Accuracy=0.735, Train AUC=0.803, Test Accuracy=0.685, Test AUC=0.728\n",
      "{'train_accuracy': 0.735, 'train_auc': 0.8, 'test_accuracy': 0.684, 'test_auc': 0.722}\n"
     ]
    }
   ],
   "source": [
    "# Supervised CCA + SVM\n",
    "# Note: supervised CCA can only keep a maximum of 2 components.\n",
    "classification_pipeline(\n",
    "\tX, y, model_class=CCA, n_components=2,\n",
    "\tclassifier_type='svm', classifier_kwargs=svm_params,\n",
    "\tn_splits=5, random_state=42, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cPCA + Logistic Regression with penalty\n",
    "classification_pipeline(\n",
    "\tX, y, model_class=CPCA, n_components=328,\n",
    "\tclassifier_type='logistic', classifier_kwargs=logistic_params,\n",
    "\tn_splits=5, random_state=42, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Best alpha = 0.1\n",
      "Fold 1: Train Accuracy=0.896, Train AUC=0.965, Test Accuracy=0.5, Test AUC=0.536\n",
      "Fold 2: Best alpha = 0.1\n",
      "Fold 2: Train Accuracy=0.894, Train AUC=0.967, Test Accuracy=0.5, Test AUC=0.578\n",
      "Fold 3: Best alpha = 0.1\n",
      "Fold 3: Train Accuracy=0.894, Train AUC=0.966, Test Accuracy=0.5, Test AUC=0.544\n",
      "Fold 4: Best alpha = 0.1\n",
      "Fold 4: Train Accuracy=0.895, Train AUC=0.965, Test Accuracy=0.5, Test AUC=0.507\n",
      "Fold 5: Best alpha = 0.1\n",
      "Fold 5: Train Accuracy=0.89, Train AUC=0.964, Test Accuracy=0.5, Test AUC=0.533\n",
      "{'train_accuracy': 0.894, 'train_auc': 0.965, 'test_accuracy': 0.5, 'test_auc': 0.54}\n"
     ]
    }
   ],
   "source": [
    "# cPCA + SVM\n",
    "classification_pipeline(\n",
    "\tX, y, model_class=CPCA, n_components=328,\n",
    "\tclassifier_type='svm', classifier_kwargs=svm_params,\n",
    "\tn_splits=5, random_state=42, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Best alpha = 0.1\n",
      "Fold 1: Train Accuracy=0.896, Train AUC=0.966, Test Accuracy=0.549, Test AUC=0.537\n"
     ]
    }
   ],
   "source": [
    "# cPCA + SVM\n",
    "classification_pipeline(\n",
    "\tX, y, model_class=CPCA, n_components=328,\n",
    "\tclassifier_type='svm', classifier_kwargs=svm_params,\n",
    "\tn_splits=5, random_state=42, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP (non-linear, 50 components) + SVM\n",
    "classification_pipeline(\n",
    "\tX, y, model_class=umap.UMAP, n_components=50,\n",
    "\tclassifier_type='svm', classifier_kwargs=svm_params,\n",
    "\tn_splits=5, random_state=42, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5381\n",
      "Train AUC: 0.5102\n",
      "Test accuracy: 0.5264\n",
      "Test AUC: 0.5289\n"
     ]
    }
   ],
   "source": [
    "# CPCA + Logistic Regression with penalty\n",
    "\n",
    "# First, split!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Dimensionality reduction\n",
    "X_train_rest = X_train[y_train == 0]  # background dataset for cPCA\n",
    "X_train_reduced, pipeline = dim_reduction_train(X_train, CPCA, n_components=2, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\tY=X_train_rest, alpha=0.5)\n",
    "X_test_reduced = dim_reduction_test(X_test, pipeline)   # project test data on \n",
    "# learned subspace, so don't provide background Y=X_test_rest or else data leakage\n",
    "\n",
    "# Classification model training\n",
    "classifier = LogisticRegression(penalty='l1', solver='saga', max_iter=5000)\n",
    "classifier.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Evaluation metrics\n",
    "evaluate_performance(classifier, X_train_reduced, y_train, X_test_reduced, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5625\n",
      "Train AUC: 0.6293\n",
      "Test accuracy: 0.5657\n",
      "Test AUC: 0.5891\n"
     ]
    }
   ],
   "source": [
    "# CPCA + Logistic Regression with penalty WITH 100 COMPONENTS\n",
    "\n",
    "# First, split!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Dimensionality reduction\n",
    "X_train_rest = X_train[y_train == 0]  # background dataset for cPCA\n",
    "X_train_reduced, pipeline = dim_reduction_train(X_train, CPCA, n_components=100, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\tY=X_train_rest, alpha=0.5)\n",
    "X_test_reduced = dim_reduction_test(X_test, pipeline)   # project test data on \n",
    "# learned subspace, so don't provide background Y=X_test_rest or else data leakage\n",
    "\n",
    "# Classification model training\n",
    "classifier = LogisticRegression(penalty='l1', solver='saga', max_iter=5000)\n",
    "classifier.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Evaluation metrics\n",
    "evaluate_performance(classifier, X_train_reduced, y_train, X_test_reduced, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kinichen/miniconda3/envs/neuro_jb_lab_env/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6053\n",
      "Train AUC: 0.5729\n",
      "Test accuracy: 0.6218\n",
      "Test AUC: 0.5937\n"
     ]
    }
   ],
   "source": [
    "# UMAP + Logistic Regression with penalty\n",
    "\n",
    "# First, split!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Dimensionality reduction\n",
    "X_train_reduced, pipeline = dim_reduction_train(X_train, umap.UMAP, n_components=2)\n",
    "X_test_reduced = dim_reduction_test(X_test, pipeline)\n",
    "\n",
    "# Classification model training\n",
    "classifier = LogisticRegression(penalty='l1', solver='saga', max_iter=5000)\n",
    "classifier.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Evaluation metrics\n",
    "evaluate_performance(classifier, X_train_reduced, y_train, X_test_reduced, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro_jb_lab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
